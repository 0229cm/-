{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFq965tgE1Rh"
      },
      "source": [
        "from tensorflow import Tensor\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
        "                                    Add, AveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "\n",
        "def relu_bn(inputs: Tensor) -> Tensor:\n",
        "    relu = ReLU()(inputs)\n",
        "    bn = BatchNormalization()(relu)\n",
        "    return bn\n",
        "\n",
        "#Creating Model\n",
        "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
        "    y = Conv2D(kernel_size=kernel_size,strides= (1 if not downsample else 2),filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
        "    y = relu_bn(y)\n",
        "    y = Conv2D(kernel_size=kernel_size,strides=1,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(y)\n",
        "\n",
        "    if downsample:\n",
        "        x = Conv2D(kernel_size=1,strides=2,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
        "\n",
        "    out = Add()([x, y])\n",
        "    out = relu_bn(out)\n",
        "    return out\n",
        "\n",
        "def create_res_net():\n",
        "    \n",
        "    inputs = Input(shape=(32, 32, 3))\n",
        "    num_filters = 64\n",
        "    \n",
        "    t = BatchNormalization()(inputs)\n",
        "    t = Conv2D(kernel_size=3,strides=1,filters=num_filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(t)\n",
        "    t = relu_bn(t)\n",
        "    \n",
        "    num_blocks_list = [2,2, 2,2]\n",
        "    for i in range(len(num_blocks_list)):\n",
        "        num_blocks = num_blocks_list[i]\n",
        "        for j in range(num_blocks):\n",
        "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
        "        num_filters *= 2\n",
        "    \n",
        "    t = AveragePooling2D(4)(t)\n",
        "    t = Flatten()(t)\n",
        "    t=Dense(512,activation='relu')(t)\n",
        "    t=BatchNormalization()(t)\n",
        "    outputs = Dense(100, activation='softmax')(t)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "    adam=Adam(learning_rate=0.001,clipnorm=1,name='adam')\n",
        "    model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccSoe3-sE1PL",
        "outputId": "6e023fb3-d880-4f3e-c402-4e7fe73e34fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
        "\n",
        "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
        "#x_train = x_train.astype('float32') / 255\n",
        "#x_test = x_test.astype('float32') / 255\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(Y_train,100)\n",
        "y_test = to_categorical(Y_test,100)\n",
        "\n",
        "model = create_res_net() \n",
        "model.summary()\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "aug_data=ImageDataGenerator(\n",
        "        rotation_range=20,     #randomly rotate images in the range (20 degrees)\n",
        "        horizontal_flip=True,  #randomly flip images\n",
        "        width_shift_range=0.1, #randomly shift images horizontally (fraction of total width)\n",
        "        shear_range = 0.2,     #Shear Intensity (Shear angle in counter-clockwise direction in degrees)\n",
        "        height_shift_range=0.1,#randomly shift images vertically (fraction of total height)\n",
        "        zoom_range=0.2,        #Range for random zoom\n",
        "        brightness_range = (0.5, 1.5))   #Range for picking a brightness shift value\n",
        "aug_data.fit(x_train)\n",
        "\n",
        "# save model after each epoch\n",
        "checkpoint = ModelCheckpoint(\"ResNet_BatchNorm_Adam.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)\n",
        "hist=model.fit(aug_data.flow(x_train, y_train, batch_size=128), batch_size=128, epochs=50, verbose=1, validation_data=(x_test, y_test),callbacks=[early,checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 32, 32, 3)    12          input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 32, 32, 64)   1792        batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_51 (ReLU)                 (None, 32, 32, 64)   0           conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 32, 32, 64)   256         re_lu_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_52 (ReLU)                 (None, 32, 32, 64)   0           conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 32, 32, 64)   256         re_lu_52[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 32, 32, 64)   0           batch_normalization_58[0][0]     \n",
            "                                                                 conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_53 (ReLU)                 (None, 32, 32, 64)   0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 32, 32, 64)   256         re_lu_53[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_54 (ReLU)                 (None, 32, 32, 64)   0           conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 32, 32, 64)   256         re_lu_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 32, 32, 64)   0           batch_normalization_60[0][0]     \n",
            "                                                                 conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_55 (ReLU)                 (None, 32, 32, 64)   0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 32, 32, 64)   256         re_lu_55[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 16, 16, 128)  73856       batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_56 (ReLU)                 (None, 16, 16, 128)  0           conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 16, 16, 128)  512         re_lu_56[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 16, 16, 128)  8320        batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 16, 16, 128)  147584      batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 16, 16, 128)  0           conv2d_93[0][0]                  \n",
            "                                                                 conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_57 (ReLU)                 (None, 16, 16, 128)  0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 16, 16, 128)  512         re_lu_57[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 16, 16, 128)  147584      batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_58 (ReLU)                 (None, 16, 16, 128)  0           conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 16, 16, 128)  512         re_lu_58[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 16, 16, 128)  147584      batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 16, 16, 128)  0           batch_normalization_64[0][0]     \n",
            "                                                                 conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_59 (ReLU)                 (None, 16, 16, 128)  0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 16, 16, 128)  512         re_lu_59[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 8, 8, 256)    295168      batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_60 (ReLU)                 (None, 8, 8, 256)    0           conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 8, 8, 256)    1024        re_lu_60[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 8, 8, 256)    33024       batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 8, 8, 256)    590080      batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 8, 8, 256)    0           conv2d_98[0][0]                  \n",
            "                                                                 conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_61 (ReLU)                 (None, 8, 8, 256)    0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 8, 8, 256)    1024        re_lu_61[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 8, 8, 256)    590080      batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_62 (ReLU)                 (None, 8, 8, 256)    0           conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 256)    1024        re_lu_62[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 8, 8, 256)    590080      batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 8, 8, 256)    0           batch_normalization_68[0][0]     \n",
            "                                                                 conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_63 (ReLU)                 (None, 8, 8, 256)    0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 8, 8, 256)    1024        re_lu_63[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 4, 4, 512)    1180160     batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_64 (ReLU)                 (None, 4, 4, 512)    0           conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 4, 4, 512)    2048        re_lu_64[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 4, 4, 512)    131584      batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 4, 4, 512)    2359808     batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 4, 4, 512)    0           conv2d_103[0][0]                 \n",
            "                                                                 conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_65 (ReLU)                 (None, 4, 4, 512)    0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 4, 4, 512)    2048        re_lu_65[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 4, 4, 512)    2359808     batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_66 (ReLU)                 (None, 4, 4, 512)    0           conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 4, 4, 512)    2048        re_lu_66[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 4, 4, 512)    2359808     batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 4, 4, 512)    0           batch_normalization_72[0][0]     \n",
            "                                                                 conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_67 (ReLU)                 (None, 4, 4, 512)    0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 4, 4, 512)    2048        re_lu_67[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 1, 1, 512)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 512)          0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 512)          262656      flatten_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 512)          2048        dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 100)          51300       batch_normalization_75[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 11,495,664\n",
            "Trainable params: 11,486,826\n",
            "Non-trainable params: 8,838\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.1167 - accuracy: 0.0736\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.06830, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 139ms/step - loss: 4.1167 - accuracy: 0.0736 - val_loss: 4.8068 - val_accuracy: 0.0683\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.6222 - accuracy: 0.1418\n",
            "Epoch 00002: val_accuracy improved from 0.06830 to 0.12430, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 3.6222 - accuracy: 0.1418 - val_loss: 4.4438 - val_accuracy: 0.1243\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.2761 - accuracy: 0.1997\n",
            "Epoch 00003: val_accuracy improved from 0.12430 to 0.24820, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 3.2761 - accuracy: 0.1997 - val_loss: 3.0343 - val_accuracy: 0.2482\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.9772 - accuracy: 0.2561\n",
            "Epoch 00004: val_accuracy improved from 0.24820 to 0.28780, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 2.9772 - accuracy: 0.2561 - val_loss: 3.1674 - val_accuracy: 0.2878\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.6971 - accuracy: 0.3053\n",
            "Epoch 00005: val_accuracy improved from 0.28780 to 0.35860, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 2.6971 - accuracy: 0.3053 - val_loss: 2.4600 - val_accuracy: 0.3586\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4679 - accuracy: 0.3526\n",
            "Epoch 00006: val_accuracy improved from 0.35860 to 0.39820, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 2.4679 - accuracy: 0.3526 - val_loss: 2.4486 - val_accuracy: 0.3982\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.2748 - accuracy: 0.3984\n",
            "Epoch 00007: val_accuracy improved from 0.39820 to 0.40320, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 2.2748 - accuracy: 0.3984 - val_loss: 2.8991 - val_accuracy: 0.4032\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0901 - accuracy: 0.4377\n",
            "Epoch 00008: val_accuracy improved from 0.40320 to 0.45340, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 2.0901 - accuracy: 0.4377 - val_loss: 2.1276 - val_accuracy: 0.4534\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9639 - accuracy: 0.4689\n",
            "Epoch 00009: val_accuracy improved from 0.45340 to 0.48830, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 1.9639 - accuracy: 0.4689 - val_loss: 1.9822 - val_accuracy: 0.4883\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.8397 - accuracy: 0.4972\n",
            "Epoch 00010: val_accuracy did not improve from 0.48830\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 1.8397 - accuracy: 0.4972 - val_loss: 1.9539 - val_accuracy: 0.4820\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7348 - accuracy: 0.5228\n",
            "Epoch 00011: val_accuracy did not improve from 0.48830\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 1.7348 - accuracy: 0.5228 - val_loss: 2.7819 - val_accuracy: 0.4702\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.6383 - accuracy: 0.5432\n",
            "Epoch 00012: val_accuracy improved from 0.48830 to 0.54330, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 1.6383 - accuracy: 0.5432 - val_loss: 1.6634 - val_accuracy: 0.5433\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5544 - accuracy: 0.5631\n",
            "Epoch 00013: val_accuracy did not improve from 0.54330\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 1.5544 - accuracy: 0.5631 - val_loss: 1.6992 - val_accuracy: 0.5368\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5414 - accuracy: 0.5658\n",
            "Epoch 00014: val_accuracy improved from 0.54330 to 0.54880, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 1.5414 - accuracy: 0.5658 - val_loss: 1.8382 - val_accuracy: 0.5488\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4057 - accuracy: 0.5964\n",
            "Epoch 00015: val_accuracy improved from 0.54880 to 0.56000, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 1.4057 - accuracy: 0.5964 - val_loss: 1.7088 - val_accuracy: 0.5600\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.3193 - accuracy: 0.6169\n",
            "Epoch 00016: val_accuracy improved from 0.56000 to 0.56520, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 1.3193 - accuracy: 0.6169 - val_loss: 1.8457 - val_accuracy: 0.5652\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2549 - accuracy: 0.6323\n",
            "Epoch 00017: val_accuracy improved from 0.56520 to 0.58170, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 1.2549 - accuracy: 0.6323 - val_loss: 1.5619 - val_accuracy: 0.5817\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1820 - accuracy: 0.6502\n",
            "Epoch 00018: val_accuracy did not improve from 0.58170\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 1.1820 - accuracy: 0.6502 - val_loss: 1.6187 - val_accuracy: 0.5770\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1265 - accuracy: 0.6661\n",
            "Epoch 00019: val_accuracy did not improve from 0.58170\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 1.1265 - accuracy: 0.6661 - val_loss: 1.8020 - val_accuracy: 0.5573\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0723 - accuracy: 0.6804\n",
            "Epoch 00020: val_accuracy improved from 0.58170 to 0.58430, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 1.0723 - accuracy: 0.6804 - val_loss: 1.6302 - val_accuracy: 0.5843\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0283 - accuracy: 0.6910\n",
            "Epoch 00021: val_accuracy improved from 0.58430 to 0.60840, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 1.0283 - accuracy: 0.6910 - val_loss: 1.4981 - val_accuracy: 0.6084\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9665 - accuracy: 0.7071\n",
            "Epoch 00022: val_accuracy did not improve from 0.60840\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 0.9665 - accuracy: 0.7071 - val_loss: 1.5776 - val_accuracy: 0.6054\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9156 - accuracy: 0.7210\n",
            "Epoch 00023: val_accuracy did not improve from 0.60840\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 0.9156 - accuracy: 0.7210 - val_loss: 1.6023 - val_accuracy: 0.6000\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8745 - accuracy: 0.7325\n",
            "Epoch 00024: val_accuracy improved from 0.60840 to 0.61450, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 0.8745 - accuracy: 0.7325 - val_loss: 1.5482 - val_accuracy: 0.6145\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8341 - accuracy: 0.7441\n",
            "Epoch 00025: val_accuracy did not improve from 0.61450\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 0.8341 - accuracy: 0.7441 - val_loss: 1.6613 - val_accuracy: 0.6021\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8033 - accuracy: 0.7546\n",
            "Epoch 00026: val_accuracy improved from 0.61450 to 0.62720, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 0.8033 - accuracy: 0.7546 - val_loss: 1.5686 - val_accuracy: 0.6272\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7550 - accuracy: 0.7644\n",
            "Epoch 00027: val_accuracy did not improve from 0.62720\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 0.7550 - accuracy: 0.7644 - val_loss: 1.6903 - val_accuracy: 0.6021\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7298 - accuracy: 0.7726\n",
            "Epoch 00028: val_accuracy did not improve from 0.62720\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 0.7298 - accuracy: 0.7726 - val_loss: 1.5985 - val_accuracy: 0.6152\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.7827\n",
            "Epoch 00029: val_accuracy did not improve from 0.62720\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 0.6923 - accuracy: 0.7827 - val_loss: 1.7693 - val_accuracy: 0.5995\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.6621 - accuracy: 0.7916\n",
            "Epoch 00030: val_accuracy improved from 0.62720 to 0.63290, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 0.6621 - accuracy: 0.7916 - val_loss: 1.5729 - val_accuracy: 0.6329\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.6306 - accuracy: 0.8011\n",
            "Epoch 00031: val_accuracy did not improve from 0.63290\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 0.6306 - accuracy: 0.8011 - val_loss: 1.6391 - val_accuracy: 0.6229\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.5992 - accuracy: 0.8132\n",
            "Epoch 00032: val_accuracy did not improve from 0.63290\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 0.5992 - accuracy: 0.8132 - val_loss: 1.6551 - val_accuracy: 0.6221\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.5856 - accuracy: 0.8137\n",
            "Epoch 00033: val_accuracy did not improve from 0.63290\n",
            "391/391 [==============================] - 53s 136ms/step - loss: 0.5856 - accuracy: 0.8137 - val_loss: 1.7081 - val_accuracy: 0.6154\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.5543 - accuracy: 0.8237\n",
            "Epoch 00034: val_accuracy did not improve from 0.63290\n",
            "391/391 [==============================] - 53s 136ms/step - loss: 0.5543 - accuracy: 0.8237 - val_loss: 1.7020 - val_accuracy: 0.6155\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.8322\n",
            "Epoch 00035: val_accuracy did not improve from 0.63290\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 0.5330 - accuracy: 0.8322 - val_loss: 1.6722 - val_accuracy: 0.6285\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.5045 - accuracy: 0.8371\n",
            "Epoch 00036: val_accuracy did not improve from 0.63290\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 0.5045 - accuracy: 0.8371 - val_loss: 1.7286 - val_accuracy: 0.6180\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.4848 - accuracy: 0.8452\n",
            "Epoch 00037: val_accuracy did not improve from 0.63290\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 0.4848 - accuracy: 0.8452 - val_loss: 1.8111 - val_accuracy: 0.6192\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.4644 - accuracy: 0.8517\n",
            "Epoch 00038: val_accuracy improved from 0.63290 to 0.63830, saving model to ResNet_BatchNorm_Adam.hdf5\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 0.4644 - accuracy: 0.8517 - val_loss: 1.6340 - val_accuracy: 0.6383\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.4424 - accuracy: 0.8597\n",
            "Epoch 00039: val_accuracy did not improve from 0.63830\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 0.4424 - accuracy: 0.8597 - val_loss: 1.6588 - val_accuracy: 0.6343\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.4360 - accuracy: 0.8600\n",
            "Epoch 00040: val_accuracy did not improve from 0.63830\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 0.4360 - accuracy: 0.8600 - val_loss: 1.7000 - val_accuracy: 0.6312\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.4199 - accuracy: 0.8652\n",
            "Epoch 00041: val_accuracy did not improve from 0.63830\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 0.4199 - accuracy: 0.8652 - val_loss: 1.7947 - val_accuracy: 0.6280\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.3978 - accuracy: 0.8723\n",
            "Epoch 00042: val_accuracy did not improve from 0.63830\n",
            "391/391 [==============================] - 53s 137ms/step - loss: 0.3978 - accuracy: 0.8723 - val_loss: 1.7538 - val_accuracy: 0.6337\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.3934 - accuracy: 0.8730\n",
            "Epoch 00043: val_accuracy did not improve from 0.63830\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 0.3934 - accuracy: 0.8730 - val_loss: 1.8574 - val_accuracy: 0.6259\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8779\n",
            "Epoch 00044: val_accuracy did not improve from 0.63830\n",
            "391/391 [==============================] - 53s 137ms/step - loss: 0.3816 - accuracy: 0.8779 - val_loss: 1.9050 - val_accuracy: 0.6171\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.3690 - accuracy: 0.8806\n",
            "Epoch 00045: val_accuracy did not improve from 0.63830\n",
            "391/391 [==============================] - 54s 137ms/step - loss: 0.3690 - accuracy: 0.8806 - val_loss: 1.8378 - val_accuracy: 0.6228\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.3601 - accuracy: 0.8835\n",
            "Epoch 00046: val_accuracy did not improve from 0.63830\n",
            "391/391 [==============================] - 53s 136ms/step - loss: 0.3601 - accuracy: 0.8835 - val_loss: 2.0426 - val_accuracy: 0.6065\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.3436 - accuracy: 0.8885\n",
            "Epoch 00047: val_accuracy did not improve from 0.63830\n",
            "391/391 [==============================] - 53s 136ms/step - loss: 0.3436 - accuracy: 0.8885 - val_loss: 1.9278 - val_accuracy: 0.6213\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.3446 - accuracy: 0.8872Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.63830\n",
            "391/391 [==============================] - 54s 138ms/step - loss: 0.3446 - accuracy: 0.8872 - val_loss: 2.0058 - val_accuracy: 0.6173\n",
            "Epoch 00048: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no_3OfjYE1NX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4UCoaOvE1K2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggaqjTf0E1Is"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR6mX90XE1GU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ynkt_OTQrSMn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP-o_LF6rSKq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaKpwSfhrSIr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdS2ofYLrSGq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQFdbG9yrSEh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}