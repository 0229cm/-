{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wo9s1kMbcoe",
        "outputId": "356d55d8-8deb-46fb-f5d9-dbd6958e07a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
        "#x_train = x_train.astype('float32') / 255\n",
        "#x_test = x_test.astype('float32') / 255\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(Y_train)\n",
        "y_test = to_categorical(Y_test)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVYPu6eqgsh7"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense,BatchNormalization,Activation,Dropout,LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model = Sequential()\n",
        "\n",
        "# Creating first block- (2 Convolution + 1 Max pool)\n",
        "model.add(Conv2D(filters= 64, kernel_size= (3,3), strides= (1,1), activation='relu', padding='same', input_shape= (32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Conv2D(filters= 64, kernel_size= (3,3), strides= (1,1), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size= (2,2), strides=(1,1)))\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "# Creating second block- (2 Convolution + 1 Max pool)\n",
        "model.add(Conv2D(filters= 128, kernel_size= (3,3), strides= (1,1), activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Conv2D(filters= 128, kernel_size= (3,3), strides= (1,1), activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size= (2,2), strides=(1,1)))\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "# Creating third block- (3 Convolution + 1 Max pool)\n",
        "model.add(Conv2D(filters= 256, kernel_size= (3,3), strides= (1,1), activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters= 256, kernel_size= (3,3), strides= (1,1),activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters= 256, kernel_size= (3,3), strides= (1,1),activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters= 256, kernel_size= (3,3), strides= (1,1), activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size= (2,2), strides=(2,2)))\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "# Creating fourth block- (3 Convolution + 1 Max pool)\n",
        "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1),activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1),activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(MaxPool2D(pool_size= (2,2), strides=(1,1)))\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "# Creating fifth block- (3 Convolution + 1 Max pool)\n",
        "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1),activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(MaxPool2D(pool_size= (2,2), strides=(1,1)))\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "# Flattening the pooled image pixels\n",
        "model.add(Flatten())\n",
        "\n",
        "# Creating 2 Dense Layers\n",
        "model.add(Dense(units= 512,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units= 512,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "# Creating an output layer\n",
        "model.add(Dense(units= 100, activation='softmax'))\n",
        "\n",
        "\n",
        "adam=Adam(learning_rate=0.0001,clipnorm=1,name='adam')\n",
        "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "#print(model.summary())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgF0caC5gseF",
        "outputId": "12e1f51d-2b3a-4a0f-9143-f43174deec83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"VGG_DropOut_Adam_weights.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)\n",
        "hist=model.fit(x_train, y_train, batch_size=128, epochs=50, verbose=1, validation_data=(x_test, y_test),callbacks=[checkpoint,early])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/391 [..............................] - ETA: 1:48 - loss: 4.0141 - accuracy: 0.1328WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1891s vs `on_train_batch_end` time: 0.3691s). Check your callbacks.\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.4140 - accuracy: 0.1984\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.24110, saving model to VGG_DropOut_Adam_weights.hdf5\n",
            "391/391 [==============================] - 242s 618ms/step - loss: 3.4140 - accuracy: 0.1984 - val_loss: 3.4590 - val_accuracy: 0.2411\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5724 - accuracy: 0.3549\n",
            "Epoch 00002: val_accuracy improved from 0.24110 to 0.32990, saving model to VGG_DropOut_Adam_weights.hdf5\n",
            "391/391 [==============================] - 240s 615ms/step - loss: 2.5724 - accuracy: 0.3549 - val_loss: 2.7606 - val_accuracy: 0.3299\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0309 - accuracy: 0.4687\n",
            "Epoch 00003: val_accuracy improved from 0.32990 to 0.40020, saving model to VGG_DropOut_Adam_weights.hdf5\n",
            "391/391 [==============================] - 240s 614ms/step - loss: 2.0309 - accuracy: 0.4687 - val_loss: 2.3569 - val_accuracy: 0.4002\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5968 - accuracy: 0.5723\n",
            "Epoch 00004: val_accuracy improved from 0.40020 to 0.45680, saving model to VGG_DropOut_Adam_weights.hdf5\n",
            "391/391 [==============================] - 242s 619ms/step - loss: 1.5968 - accuracy: 0.5723 - val_loss: 2.1012 - val_accuracy: 0.4568\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2039 - accuracy: 0.6757\n",
            "Epoch 00005: val_accuracy improved from 0.45680 to 0.47310, saving model to VGG_DropOut_Adam_weights.hdf5\n",
            "391/391 [==============================] - 240s 613ms/step - loss: 1.2039 - accuracy: 0.6757 - val_loss: 2.0324 - val_accuracy: 0.4731\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8241 - accuracy: 0.7854\n",
            "Epoch 00006: val_accuracy improved from 0.47310 to 0.48930, saving model to VGG_DropOut_Adam_weights.hdf5\n",
            "391/391 [==============================] - 240s 614ms/step - loss: 0.8241 - accuracy: 0.7854 - val_loss: 2.0388 - val_accuracy: 0.4893\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.4853 - accuracy: 0.8890\n",
            "Epoch 00007: val_accuracy improved from 0.48930 to 0.49760, saving model to VGG_DropOut_Adam_weights.hdf5\n",
            "391/391 [==============================] - 240s 613ms/step - loss: 0.4853 - accuracy: 0.8890 - val_loss: 2.0168 - val_accuracy: 0.4976\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.2489 - accuracy: 0.9537\n",
            "Epoch 00008: val_accuracy did not improve from 0.49760\n",
            "391/391 [==============================] - 238s 609ms/step - loss: 0.2489 - accuracy: 0.9537 - val_loss: 2.0815 - val_accuracy: 0.4965\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 0.9816\n",
            "Epoch 00009: val_accuracy improved from 0.49760 to 0.50700, saving model to VGG_DropOut_Adam_weights.hdf5\n",
            "391/391 [==============================] - 240s 614ms/step - loss: 0.1270 - accuracy: 0.9816 - val_loss: 2.1107 - val_accuracy: 0.5070\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9934\n",
            "Epoch 00010: val_accuracy did not improve from 0.50700\n",
            "391/391 [==============================] - 239s 611ms/step - loss: 0.0631 - accuracy: 0.9934 - val_loss: 2.1790 - val_accuracy: 0.5028\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 0.9967\n",
            "Epoch 00011: val_accuracy improved from 0.50700 to 0.52100, saving model to VGG_DropOut_Adam_weights.hdf5\n",
            "391/391 [==============================] - 240s 613ms/step - loss: 0.0381 - accuracy: 0.9967 - val_loss: 2.1057 - val_accuracy: 0.5210\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.9961\n",
            "Epoch 00012: val_accuracy did not improve from 0.52100\n",
            "391/391 [==============================] - 239s 611ms/step - loss: 0.0347 - accuracy: 0.9961 - val_loss: 2.2762 - val_accuracy: 0.4986\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0705 - accuracy: 0.9890\n",
            "Epoch 00013: val_accuracy did not improve from 0.52100\n",
            "391/391 [==============================] - 239s 611ms/step - loss: 0.0705 - accuracy: 0.9890 - val_loss: 2.3732 - val_accuracy: 0.4940\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.9755\n",
            "Epoch 00014: val_accuracy did not improve from 0.52100\n",
            "391/391 [==============================] - 239s 610ms/step - loss: 0.1212 - accuracy: 0.9755 - val_loss: 2.3925 - val_accuracy: 0.4861\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9903\n",
            "Epoch 00015: val_accuracy did not improve from 0.52100\n",
            "391/391 [==============================] - 238s 609ms/step - loss: 0.0599 - accuracy: 0.9903 - val_loss: 2.3333 - val_accuracy: 0.5054\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9974\n",
            "Epoch 00016: val_accuracy did not improve from 0.52100\n",
            "391/391 [==============================] - 238s 608ms/step - loss: 0.0250 - accuracy: 0.9974 - val_loss: 2.2908 - val_accuracy: 0.5126\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9987\n",
            "Epoch 00017: val_accuracy did not improve from 0.52100\n",
            "391/391 [==============================] - 238s 609ms/step - loss: 0.0140 - accuracy: 0.9987 - val_loss: 2.3145 - val_accuracy: 0.5196\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9886\n",
            "Epoch 00018: val_accuracy did not improve from 0.52100\n",
            "391/391 [==============================] - 238s 608ms/step - loss: 0.0525 - accuracy: 0.9886 - val_loss: 2.7046 - val_accuracy: 0.4608\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9761\n",
            "Epoch 00019: val_accuracy did not improve from 0.52100\n",
            "391/391 [==============================] - 240s 614ms/step - loss: 0.1018 - accuracy: 0.9761 - val_loss: 2.5519 - val_accuracy: 0.4812\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9941\n",
            "Epoch 00020: val_accuracy did not improve from 0.52100\n",
            "391/391 [==============================] - 238s 609ms/step - loss: 0.0352 - accuracy: 0.9941 - val_loss: 2.4349 - val_accuracy: 0.5075\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9983\n",
            "Epoch 00021: val_accuracy did not improve from 0.52100\n",
            "Restoring model weights from the end of the best epoch.\n",
            "391/391 [==============================] - 239s 611ms/step - loss: 0.0133 - accuracy: 0.9983 - val_loss: 2.3508 - val_accuracy: 0.5201\n",
            "Epoch 00021: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTjTkAQugscF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9lMf4zibcmi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uJ80LeusXDX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fN69iLnsXA9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfNqgO-qsW--"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uACXOG1nsW8y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7Z2cznNsW6Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwLjMsGtsW4b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}